import json
import logging
import re
import os
import time
from openai import OpenAI
from ToolExecutor import ToolExecutor

# å°è¯•ä»å¤–éƒ¨å¯¼å…¥æ¨¡æ¿
try:
    from prompt_jifen import REACT_PROMPT_TEMPLATE
except ImportError:
    # å…œåº•æ¨¡æ¿
    REACT_PROMPT_TEMPLATE = "Question: {question}\nHistory: {history}\nTools: {tools}"

class ReActEngine:
    def __init__(self):
        # åŸºç¡€é…ç½®ï¼šåªå…³å¿ƒå¦‚ä½•è¿æ¥å¤§æ¨¡å‹
        api_key = os.getenv("LLM_API_KEY")
        base_url = os.getenv("LLM_BASE_URL")
        self.model = os.getenv("LLM_MODEL_ID", "gemini-3-flash-preview-free")
        
        if not api_key:
            raise ValueError("âŒ ç¯å¢ƒå˜é‡ä¸­æœªæ‰¾åˆ° LLM_API_KEY")

        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.executor = ToolExecutor()
        self.max_steps = 5  # ReAct æ¨ç†è½®æ¬¡ä¸Šé™

    def _render_prompt(self, formatted_question):
        """
        çº¯ç²¹çš„æ¨¡æ¿æ¸²æŸ“é€»è¾‘ï¼šå°†å¤–éƒ¨ä¼ æ¥çš„ question ä¸ç¯å¢ƒå‚æ•°å¯¹é½
        """
        gold_threshold = os.getenv("GOLD_THRESHOLD", "200")
        exp_threshold = os.getenv("EXP_THRESHOLD", "150")
        
        # å®šä¹‰æ¨¡æ¿ä¸­æ‰€æœ‰å ä½ç¬¦çš„å¯¹åº”å…³ç³»
        render_data = {
            "question": formatted_question,
            "history": "å®¡è®¡å¼€å§‹ï¼Œæ­£åœ¨åˆ†æåˆæ­¥çº¿ç´¢...",
            "tools": "- get_user_points[userName]: ã€æ ¸å¿ƒå·¥å…·ã€‘æŸ¥è¯¢ç›®æ ‡ç”¨æˆ·çš„ç§¯åˆ†/é‡‘å¸æµæ°´è®°å½•ã€‚",
            "gold_threshold": gold_threshold,
            "exp_threshold": exp_threshold,
            "current_date": time.strftime("%Y-%m-%d")
        }

        # è‡ªåŠ¨æå–æ¨¡æ¿é‡ŒçœŸæ­£å­˜åœ¨çš„å˜é‡ï¼Œé¿å… KeyError
        keys = re.findall(r'\{(\w+)\}', REACT_PROMPT_TEMPLATE)
        final_data = {k: render_data.get(k, f"[{k} Missing]") for k in keys}
        
        return REACT_PROMPT_TEMPLATE.format(**final_data)

    def run_audit(self, formatted_question):
        """
        Engine çš„æ ¸å¿ƒï¼šåªè´Ÿè´£å¯¹è¯é€»è¾‘å’Œæ¨¡å‹è°ƒç”¨
        formatted_question: å·²ç»ç”±å¤–éƒ¨(tools.py/main.py)å°è£…å¥½çš„æ–‡æœ¬æè¿°
        """
        # 1. æ¸²æŸ“æœ€ç»ˆå‘é€ç»™ AI çš„ Prompt
        prompt = self._render_prompt(formatted_question)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å•†åŸç§¯åˆ†å®¡è®¡ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ Thought/Action æ ¼å¼è¿›è¡Œé€»è¾‘æ¨ç†ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        logging.info("ğŸ§  AI å¼•æ“å·²æ¥æ”¶å®¡è®¡ä»»åŠ¡ï¼Œæ­£åœ¨å¯åŠ¨ ReAct é€»è¾‘...")

        # 2. ReAct å¾ªç¯
        for step in range(self.max_steps):
            try:
                # ğŸ›‘ å¼ºåˆ¶é™é€Ÿï¼šå…è´¹æ¨¡å‹æ¯ä¸€æ­¥ä¹‹é—´å¿…é¡»ä¼‘æ¯ 60 ç§’ï¼Œå½»åº•æœç» 429
                if step > 0:
                    logging.info(f"ğŸ’¤ API é™é€Ÿä¿æŠ¤ï¼šä¼‘çœ  60 ç§’åè¿›è¡Œç¬¬ {step+1} æ­¥æ€è€ƒ...")
                    time.sleep(60)

                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.1  # å®¡è®¡ä»»åŠ¡éœ€è¦é«˜åº¦ç¡®å®šæ€§ï¼Œè°ƒä½æ¸©åº¦
                )
                
                content = response.choices[0].message.content
                print(f"\n--- AI æ€è€ƒ Step {step+1} ---\n{content}")

                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if "Finish[" in content or "Final Answer:" in content:
                    return content

                # è§£æ Action: tool_name[arguments]
                action_match = re.search(r"Action:\s*(\w+)\[(.*?)\]", content, re.DOTALL)
                
                if action_match:
                    tool_name = action_match.group(1)
                    tool_args = action_match.group(2).strip().replace('"', '').replace("'", "")
                    
                    # è°ƒåº¦å·¥å…·æ‰§è¡Œ
                    observation = self.executor.execute(tool_name, tool_args)
                    
                    # å°†æ€è€ƒå’Œè§‚å¯Ÿè®°å½•å­˜å…¥å¯¹è¯å†å²
                    messages.append({"role": "assistant", "content": content})
                    messages.append({"role": "user", "content": f"Observation: {observation}"})
                else:
                    # å¦‚æœ AI è¾“å‡ºæ ¼å¼ä¸å¯¹ï¼Œå¼•å¯¼å®ƒç»™å‡ºç»“è®º
                    if step < self.max_steps - 1:
                        messages.append({"role": "assistant", "content": content})
                        messages.append({"role": "user", "content": "è¯·ç»§ç»­æŒ‰ç…§æ ¼å¼è¾“å‡º Action æˆ–ç›´æ¥ç»™å‡º Finish[] ç»“è®ºã€‚"})
                    else:
                        return content

            except Exception as e:
                # é’ˆå¯¹ 429 çš„æœ€åä¸€é“é˜²çº¿
                if "429" in str(e):
                    logging.warning("âš ï¸ ä»ç„¶è§¦å‘äº†é¢‘ç‡é™åˆ¶ï¼Œæ·±åº¦ä¼‘çœ  70s åå°è¯•é‡è¯•...")
                    time.sleep(70)
                    continue 
                return f"å¼•æ“å†…éƒ¨æ•…éšœ: {str(e)}"

        return "å®¡è®¡ä¸­æ­¢ï¼šè¶…è¿‡æœ€å¤§æ¨ç†æ­¥æ•°ã€‚"